{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import requests\n",
    "import random\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32296, 4)\n",
      "(75850, 2) (32295, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(       child     parent\n",
       " 0  n02119789  n02118333\n",
       " 1  n02478875  n02471300\n",
       " 2  n02473983  n02471762\n",
       " 3  n02100735  n02100399\n",
       " 4  n02390258  n02374149,\n",
       "                                                gloss       wnid  \\\n",
       " 0  (botany) a living organism lacking the power o...  n00017222   \n",
       " 1  photosynthetic or plant constituent of plankto...  n01383896   \n",
       " 2                                  unicellular algae  n01384084   \n",
       " 3  microscopic unicellular marine or freshwater c...  n01401106   \n",
       " 4  microscopic plants; bacteria are often conside...  n11530008   \n",
       " \n",
       "                       words  \n",
       " 0  plant, flora, plant life  \n",
       " 1             phytoplankton  \n",
       " 2          planktonic algae  \n",
       " 3                    diatom  \n",
       " 4                microflora  )"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnids_pc=pd.read_csv('./wnids_parent_child.csv')\n",
    "wnids_pc=wnids_pc.drop(labels=['Unnamed: 0'],axis=1)\n",
    "x=pd.read_csv('./words_wnids_gloss_imagenet.csv')\n",
    "print(x.shape)\n",
    "xml_dataframe=x.dropna(how='any')\n",
    "xml_dataframe=xml_dataframe.drop(labels=['Unnamed: 0'],axis=1)\n",
    "print(wnids_pc.shape,xml_dataframe.shape)\n",
    "wnids_pc.head(),xml_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 Updating csv..\n",
      "20000 Updating csv..\n",
      "30000 Updating csv..\n",
      "40000 Updating csv..\n",
      "50000 Updating csv..\n",
      "60000 Updating csv..\n",
      "70000 Updating csv..\n",
      "80000 Updating csv..\n",
      "90000 Updating csv..\n",
      "100000 Updating csv..\n",
      "110000 Updating csv..\n",
      "120000 Updating csv..\n",
      "130000 Updating csv..\n",
      "140000 Updating csv..\n",
      "150000 Updating csv..\n",
      "160000 Updating csv..\n",
      "170000 Updating csv..\n",
      "180000 Updating csv..\n",
      "190000 Updating csv..\n",
      "200000 Updating csv..\n",
      "210000 Updating csv..\n",
      "220000 Updating csv..\n",
      "230000 Updating csv..\n",
      "240000 Updating csv..\n",
      "250000 Updating csv..\n",
      "260000 Updating csv..\n",
      "270000 Updating csv..\n",
      "280000 Updating csv..\n",
      "290000 Updating csv..\n",
      "300000 Updating csv..\n",
      "310000 Updating csv..\n",
      "320000 Updating csv..\n",
      "330000 Updating csv..\n",
      "340000 Updating csv..\n",
      "350000 Updating csv..\n",
      "360000 Updating csv..\n",
      "370000 Updating csv..\n",
      "380000 Updating csv..\n",
      "390000 Updating csv..\n",
      "400000 Updating csv..\n"
     ]
    }
   ],
   "source": [
    "#load glove_txt of 100d\n",
    "#build a dataframe with 'word' and dim-data.\n",
    "fd=open('./glove.6B\\glove.6B.100d.txt','r',encoding='utf-8')\n",
    "dim=100\n",
    "\n",
    "word_embeddings=pd.DataFrame()\n",
    "words_list=[]\n",
    "rep_list=np.zeros((1,dim))\n",
    "total_words=0\n",
    "\n",
    "def update_dataframe(line):\n",
    "    #first word is word.\n",
    "    #the rest of them to be converted to float and made to a list.\n",
    "    global word_embeddings,words_list,rep_list,total_words\n",
    "    line=line.split()\n",
    "    words_list.append(line[0])\n",
    "    rep_row=np.array([float(x) for x in line[1:]]).reshape(1,dim)\n",
    "    rep_list=np.append(rep_list,rep_row,axis=0)\n",
    "    if(rep_list.shape[0]%10000==0):\n",
    "        total_words+=10000\n",
    "        print(total_words,\"Updating csv..\")\n",
    "        word_embeddings=pd.DataFrame(rep_list[1:,:])\n",
    "        word_embeddings['words']=words_list\n",
    "        words_list=[]\n",
    "        rep_list=np.zeros((1,dim))\n",
    "        word_embeddings.to_csv('./word_embeddings_100d.csv',mode='a', header=False)\n",
    "    \n",
    "while(True):\n",
    "    line=fd.readline()\n",
    "    if(not line):\n",
    "        break\n",
    "    update_dataframe(line)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#once that is done - get all the gloss vector and 'word' embeddings.\n",
    "#save with wnids and 'words'\n",
    "word_embeddings=pd.read_csv('./word_embeddings_100d.csv',header=None)\n",
    "word_embeddings=word_embeddings.drop(labels=[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.038194</td>\n",
       "      <td>-0.244870</td>\n",
       "      <td>0.72812</td>\n",
       "      <td>-0.399610</td>\n",
       "      <td>0.083172</td>\n",
       "      <td>0.043953</td>\n",
       "      <td>-0.391410</td>\n",
       "      <td>0.334400</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>0.087459</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017099</td>\n",
       "      <td>-0.389840</td>\n",
       "      <td>0.87424</td>\n",
       "      <td>-0.72569</td>\n",
       "      <td>-0.51058</td>\n",
       "      <td>-0.520280</td>\n",
       "      <td>-0.14590</td>\n",
       "      <td>0.82780</td>\n",
       "      <td>0.270620</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.107670</td>\n",
       "      <td>0.110530</td>\n",
       "      <td>0.59812</td>\n",
       "      <td>-0.543610</td>\n",
       "      <td>0.673960</td>\n",
       "      <td>0.106630</td>\n",
       "      <td>0.038867</td>\n",
       "      <td>0.354810</td>\n",
       "      <td>0.06351</td>\n",
       "      <td>-0.094189</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.722600</td>\n",
       "      <td>0.375490</td>\n",
       "      <td>0.44410</td>\n",
       "      <td>-0.99059</td>\n",
       "      <td>0.61214</td>\n",
       "      <td>-0.351110</td>\n",
       "      <td>-0.83155</td>\n",
       "      <td>0.45293</td>\n",
       "      <td>0.082577</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.339790</td>\n",
       "      <td>0.209410</td>\n",
       "      <td>0.46348</td>\n",
       "      <td>-0.647920</td>\n",
       "      <td>-0.383770</td>\n",
       "      <td>0.038034</td>\n",
       "      <td>0.171270</td>\n",
       "      <td>0.159780</td>\n",
       "      <td>0.46619</td>\n",
       "      <td>-0.019169</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.674120</td>\n",
       "      <td>-0.068895</td>\n",
       "      <td>0.53604</td>\n",
       "      <td>-0.87773</td>\n",
       "      <td>0.31802</td>\n",
       "      <td>-0.392420</td>\n",
       "      <td>-0.23394</td>\n",
       "      <td>0.47298</td>\n",
       "      <td>-0.028803</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.152900</td>\n",
       "      <td>-0.242790</td>\n",
       "      <td>0.89837</td>\n",
       "      <td>0.169960</td>\n",
       "      <td>0.535160</td>\n",
       "      <td>0.487840</td>\n",
       "      <td>-0.588260</td>\n",
       "      <td>-0.179820</td>\n",
       "      <td>-1.35810</td>\n",
       "      <td>0.425410</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018488</td>\n",
       "      <td>-0.267570</td>\n",
       "      <td>0.72700</td>\n",
       "      <td>-0.59363</td>\n",
       "      <td>-0.34839</td>\n",
       "      <td>-0.560940</td>\n",
       "      <td>-0.59100</td>\n",
       "      <td>1.00390</td>\n",
       "      <td>0.206640</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.189700</td>\n",
       "      <td>0.050024</td>\n",
       "      <td>0.19084</td>\n",
       "      <td>-0.049184</td>\n",
       "      <td>-0.089737</td>\n",
       "      <td>0.210060</td>\n",
       "      <td>-0.549520</td>\n",
       "      <td>0.098377</td>\n",
       "      <td>-0.20135</td>\n",
       "      <td>0.342410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058617</td>\n",
       "      <td>-0.318690</td>\n",
       "      <td>-0.61419</td>\n",
       "      <td>-0.62393</td>\n",
       "      <td>-0.41548</td>\n",
       "      <td>-0.038175</td>\n",
       "      <td>-0.39804</td>\n",
       "      <td>0.47647</td>\n",
       "      <td>-0.159830</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2        3         4         5         6         7  \\\n",
       "0 -0.038194 -0.244870  0.72812 -0.399610  0.083172  0.043953 -0.391410   \n",
       "1 -0.107670  0.110530  0.59812 -0.543610  0.673960  0.106630  0.038867   \n",
       "2 -0.339790  0.209410  0.46348 -0.647920 -0.383770  0.038034  0.171270   \n",
       "3 -0.152900 -0.242790  0.89837  0.169960  0.535160  0.487840 -0.588260   \n",
       "4 -0.189700  0.050024  0.19084 -0.049184 -0.089737  0.210060 -0.549520   \n",
       "\n",
       "          8        9        10  ...          92        93       94       95  \\\n",
       "0  0.334400 -0.57545  0.087459  ...   -0.017099 -0.389840  0.87424 -0.72569   \n",
       "1  0.354810  0.06351 -0.094189  ...   -0.722600  0.375490  0.44410 -0.99059   \n",
       "2  0.159780  0.46619 -0.019169  ...   -0.674120 -0.068895  0.53604 -0.87773   \n",
       "3 -0.179820 -1.35810  0.425410  ...   -0.018488 -0.267570  0.72700 -0.59363   \n",
       "4  0.098377 -0.20135  0.342410  ...    0.058617 -0.318690 -0.61419 -0.62393   \n",
       "\n",
       "        96        97       98       99       100  words  \n",
       "0 -0.51058 -0.520280 -0.14590  0.82780  0.270620    the  \n",
       "1  0.61214 -0.351110 -0.83155  0.45293  0.082577      ,  \n",
       "2  0.31802 -0.392420 -0.23394  0.47298 -0.028803      .  \n",
       "3 -0.34839 -0.560940 -0.59100  1.00390  0.206640     of  \n",
       "4 -0.41548 -0.038175 -0.39804  0.47647 -0.159830     to  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the last column - for words.\n",
    "word_embeddings=word_embeddings.rename(columns={101:'words'})\n",
    "word_embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Written to csv..\n",
      "20 Written to csv..\n",
      "30 Written to csv..\n",
      "40 Written to csv..\n",
      "50 Written to csv..\n",
      "60 Written to csv..\n",
      "70 Written to csv..\n",
      "80 Written to csv..\n",
      "90 Written to csv..\n",
      "100 Written to csv..\n",
      "110 Written to csv..\n",
      "120 Written to csv..\n",
      "130 Written to csv..\n",
      "140 Written to csv..\n",
      "150 Written to csv..\n",
      "160 Written to csv..\n",
      "170 Written to csv..\n",
      "180 Written to csv..\n",
      "190 Written to csv..\n",
      "200 Written to csv..\n",
      "210 Written to csv..\n",
      "220 Written to csv..\n",
      "230 Written to csv..\n",
      "240 Written to csv..\n",
      "250 Written to csv..\n",
      "260 Written to csv..\n",
      "270 Written to csv..\n",
      "280 Written to csv..\n",
      "290 Written to csv..\n",
      "300 Written to csv..\n",
      "310 Written to csv..\n",
      "320 Written to csv..\n",
      "330 Written to csv..\n",
      "340 Written to csv..\n",
      "350 Written to csv..\n",
      "360 Written to csv..\n",
      "370 Written to csv..\n",
      "380 Written to csv..\n",
      "390 Written to csv..\n",
      "400 Written to csv..\n",
      "410 Written to csv..\n",
      "420 Written to csv..\n",
      "430 Written to csv..\n",
      "440 Written to csv..\n",
      "450 Written to csv..\n",
      "460 Written to csv..\n",
      "470 Written to csv..\n",
      "480 Written to csv..\n",
      "490 Written to csv..\n",
      "500 Written to csv..\n",
      "510 Written to csv..\n",
      "520 Written to csv..\n",
      "530 Written to csv..\n",
      "540 Written to csv..\n",
      "550 Written to csv..\n",
      "560 Written to csv..\n",
      "570 Written to csv..\n",
      "580 Written to csv..\n",
      "590 Written to csv..\n",
      "600 Written to csv..\n",
      "610 Written to csv..\n",
      "620 Written to csv..\n",
      "630 Written to csv..\n",
      "640 Written to csv..\n",
      "650 Written to csv..\n",
      "660 Written to csv..\n",
      "670 Written to csv..\n",
      "680 Written to csv..\n",
      "690 Written to csv..\n",
      "700 Written to csv..\n",
      "710 Written to csv..\n",
      "720 Written to csv..\n",
      "730 Written to csv..\n",
      "740 Written to csv..\n",
      "750 Written to csv..\n",
      "760 Written to csv..\n",
      "770 Written to csv..\n",
      "780 Written to csv..\n",
      "790 Written to csv..\n",
      "800 Written to csv..\n",
      "810 Written to csv..\n",
      "820 Written to csv..\n",
      "830 Written to csv..\n",
      "840 Written to csv..\n",
      "850 Written to csv..\n",
      "860 Written to csv..\n",
      "870 Written to csv..\n",
      "880 Written to csv..\n",
      "890 Written to csv..\n",
      "900 Written to csv..\n",
      "910 Written to csv..\n",
      "920 Written to csv..\n",
      "930 Written to csv..\n",
      "940 Written to csv..\n",
      "950 Written to csv..\n",
      "960 Written to csv..\n"
     ]
    }
   ],
   "source": [
    "#build representation for each gloss.\n",
    "#Concatenate the new df to the xml_dataframe\n",
    "glosses=xml_dataframe['gloss'].tolist()\n",
    "glosses_arr=np.zeros((1,100))\n",
    "\n",
    "file_out=open('gloss_conversion.txt','w')\n",
    "\n",
    "def preprocess(text):\n",
    "    text=re.sub(r'[^a-zA-Z0-9.\\s]','',text)\n",
    "    return text.split()\n",
    "\n",
    "def sumup(tokens):\n",
    "    global word_embeddings\n",
    "    gloss_rep=np.zeros((1,100))\n",
    "    for tok in tokens:\n",
    "        try:\n",
    "            #print(tok,file=file_out)\n",
    "            rep=word_embeddings.loc[word_embeddings['words']==tok,word_embeddings.columns!='words'].as_matrix()\n",
    "            gloss_rep=gloss_rep+rep\n",
    "        except:\n",
    "            print(sys.exc_info()[1],file=file_out)\n",
    "            print(\"Missing tok.. \",tok,file=file_out)\n",
    "            \n",
    "    return gloss_rep/len(tokens) #normalize this to nullify effect of number of tokens in the string.        \n",
    "i=0\n",
    "for gloss_ in glosses:\n",
    "    print(i,gloss_,file=file_out)\n",
    "    i+=1\n",
    "    tokens=preprocess(gloss_)\n",
    "    rep=sumup(tokens) \n",
    "    glosses_arr=np.append(glosses_arr,rep,axis=0)\n",
    "    if(i%10==0):\n",
    "        print(i,\"Written to csv..\")\n",
    "        full_df=pd.DataFrame(glosses_arr[1:,:])\n",
    "        glosses_arr=np.zeros((1,100))\n",
    "        full_df.to_csv('./words_wnids_gloss_embeddings.csv',mode='a',header=False)\n",
    "\n",
    "file_out.close()    \n",
    "#full_df=pd.concat([xml_dataframe,glosses_df],axis=0)\n",
    "#print(full_df.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
